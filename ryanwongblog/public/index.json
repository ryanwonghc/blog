[{"categories":["Visualization"],"contents":"Overview Link to Github Repository\nFrom Bakermat to John Newman, EA Sport\u0026rsquo;s FIFA games have introduced me to countless new artists and iconic songs across genres that have come to define my childhood. Ask any avid FIFA player, and they will likely tell you the same. FIFA soundtracks hold a unique significance in the realm of sports and entertainment- they offer a glimpse into the collective music trends and tastes of a global community.\nThis project aims to identify the music selection criteria for songs in FIFA playlists and how this criteria has evolved over time.\nTools/Libraries Used Python: Spotipy, Pandas, NumPy, Matplotlib, Seaborn Analyzing Past FIFA Playlists I used Spotipy to access Spotify data for songs from 10 FIFA playlists (2014-2023). The data I pulled can be broadly split into three categories:\nSong data Song popularity, length, whether or not it\u0026rsquo;s marked explicit Song audio data: a list of a song\u0026rsquo;s audio features, including variables such as danceability, loudness, and tempo Album data Album release date, whether the song was released as a single (if album only has one song in it), album popularity I was unable to find the data for the song release date, so although this is not always the case, I am making the assumption that the song was released on the same date as the album Artist data Artist popularity, number of followers, and genre classification I was unable to find song specific genre data, so I am making the assumption that each song is classified under the same genre as its artist Song Genre Data Most Frequent Song Genres In FIFA Playlists FIFA playlists contain songs across a diverse set of genres but a few genres stand out in particular as a popular choice for EA Sport's picks: House Pop Hip Hop Indie, dance, alternative, modern, and rock are also popular keywords. Additionally, although not as prominent, we also see a few region specific keywords, namely: Australian, UK, Belgian, French, Dutch, English, Nigerian, and Latino.\n2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 Wordclouds of the Most Frequent Song Genres Each Year Taking a closer look at how genre choices have changed over time, we arrive at several insights:\nGenre choice has definitely evolved over time. Categories such as House, Dance, and Rock went from being extremely popular in 2014 to being all but phased out by 2015. They were replaced by Indie, Pop, and Alternative, which are still the dominant categories today. It\u0026rsquo;s interesting that although house music was not a popular choice for most of the selected timespan, it is such a big part of the overall wordcloud. This suggests that it was extremely prominent when it was in fashion back in 2014. Hip hop has remained consistently popular throughout the 10 years. From 2020 onwards, there seems to be a more diverse mix of music in the playlist (popular genres are not as overwhelmingly dominant in the wordclouds) 2020 appeared to be a year with a very diverse selection of music- the sizes of the genres are more evenly spread out in the 2020 wordcloud. Song and Album Data Due to the abundance of new music every year and the propensity of FIFA playlists to reflect the most current musical trends, it would make sense that FIFA playlists each year are curated with songs released within the past year. This is evidenced in the chart below- at least 75% of the songs picked in each year\u0026rsquo;s playlist were released within 1 year of the playlist compilation date.\nThe chart assumes that the playlist for each year was compiled on the first day of the year (eg. 2014-01-01). There are several negative numbers here, which is due to instances of the song being released prior to the album it is on (and it was assumed that the song and album release day are the same). The median time elapsed hovers consistently at around 200 days prior to playlist release. 2023\u0026rsquo;s playlist had a median time elapsed of 268 days, which is significantly higher than the 200 days mark from previous years. This however may be due to the fact that the 2023 playlist was much larger than recent years (81 songs compared to 30-40 songs in years prior). As a result, EA Sports may have felt that it was appropriate to add more \u0026ldquo;throwback\u0026rdquo; songs on top of the songs from 2023. EA Sports also released a World Cup playlist for FIFA 2023 which contained songs from prior playlists, which could suggest an emphasis on nostalgia and older songs.\nIn the above chart, the bands represent 1 standard deviation. There seems to be a wide range of song lengths, but most are 2.5 to 5 minutes long, which reflects the average song length in general. The average song length seems to be trending slightly downwards, but that could just be reflective of overall industry trends.\nGiven that FIFA games are rated E for Everyone, it may be the case the playlist avoids explicit songs. This was definitely the case in 2014, with only 1 song being marked as explicit. However, though still a minority, the number of explicit songs as well as the proportion of songs in the playlist has been trending upwards. At the peak in 2022, a third of the playlist\u0026rsquo;s songs were marked as explicit.\nI was hesitant to read too deeply into popularity scores because I suspect that a song\u0026rsquo;s placement in the FIFA playlist heavily impacts its popularity score by increasing listenership. In the chart above, I plotted each song\u0026rsquo;s popularity against its album popularity score. Points above the dotted line indicate that the album is more popular than the song, which would suggest that there are more popular tracks on the album (ie. the song was not the most popular song on the album). In the chart, we see there are more points under the line (48% under line, 20% over line), meaning that songs in FIFA playlists typically are the most popular songs in its album.\nWe see that on average, points above the line are farther away from the line than points under the line. The farther above the line a song is, the less popular it is compared to the most popular song in the album. To illustrate this, the purple point on the graph represents the song \u0026ldquo;People\u0026rdquo; by Kungs and The Knocks. That song has 4.2M plays on Spotify, which pales in comparison to \u0026ldquo;Never Going Home\u0026rdquo; and \u0026ldquo;Clap Your Hands\u0026rdquo; in the album which have 265M and 118M plays respectively.\nAbout 30% of songs have a popularity of 0. Since recent plays weigh more in Spotify\u0026rsquo;s popularity scoring algorithm, This suggests that they haven\u0026rsquo;t been played recently. The percentage of songs with a popularity score of 0 each year is illustrated in the chart below:\nThis suggests that on average, the older the songs are, the less popular they get, which makes sense. However, it is surprising that the percentage isn\u0026rsquo;t higher for the older playlists: except for 2014 (51% 0 popularity), a majority of each year\u0026rsquo;s playlists have a non-zero popularity score. Whether or not the FIFA game is responsible for the sustained plays is unclear.\nArtist Data I elected to look at artist follower count over artist popularity score to determine artist popularity because I am making the assumption that people only choose to follow an artist if they are interested in their music. In contrast, since the artist\u0026rsquo;s popularity score is calculated using the popularity scores of their music, an artist\u0026rsquo;s popularity score can be temporarily inflated by their song being selected to appear in the FIFA playlist as it will receive more plays.\nArtist Follower Count Distribution (Logarithmic Scale) In the above chart, we see that in the earlier years (2014-2018), distribution of artist follower count was more left skewed, meaning there was an emphasis on selecting songs from more heavily followed artists. Nowadays, there is more representation from artists with different sized followings. In more recent years, FIFA has starting including artists with smaller followings (follower count \u0026lt; 1000), though it is still a small proportion of the playlist.\nAccording to Chartmasters, the 100th most followed artist on Spotify is 2pac with a follower count of 16,362,807. Given that FIFA is such a mainstream game, I assumed they would pick mainstream music. However, top 100 artists only make up 1.5% of the playlist. Going a step down, artists with 1M+ followers only make up 25% of the playlist (75th percentile). This is illustrated in the chart below:\nFrom the chart, we can also see the 25th percentile for follower count is around 50,000.\nAudio Data Spotify\u0026rsquo;s audio data consists of 12 different audio features measuring factors such as a song\u0026rsquo;s energy, instrumentalness, and key. See Spotify\u0026rsquo;s API reference page for how to interpret audio data. I used the findings in this website and correlated article, which contained analyses on the distributions of each of the audio features, to serve as a baseline to compare FIFA playlist audio features to.\nIn the chart above, we can see that over the years, FIFA is fairly consistent with song selection. There isn\u0026rsquo;t too much deviation in most features- the biggest variations I can see are in mode, danceability, and energy. The following charts allow us to get a clearer understanding of how FIFA\u0026rsquo;s selection of songs evolve over time.\nMode This variable measures the modality (major or minor) of the track, with 1 being major and 0 being minor. We see that there has been a fairly large deviation in EA Sport\u0026rsquo;s propensity to select songs in major or minor key over the year, with no obvious trend year over year (this is more clear in the chart below). This shows the diversity in music selection. Almost every year though has an average score \u0026gt; 0.5, indicating that there is a larger selection of songs in a major key. This may be because major scales and chord progressions do a better job of relating happy or up-beat emotions.\nEnergy Compared to the median energy score of 0.465, we see that FIFA songs are typically extremely energetic (1.5-2x the score on average). This may be because associating high energy music with your game gives gamers more energy when playing the game, which is a positive. We do see though that energy scores are trending down over time, which make sense given the shift from genres such as House to genres such as Indie.\nDanceability, Tempo Similar to the Energy section above, we see Tempo trending downwards but still largely above the median (115). Interestingly, it seems that danceability is trending in the opposite direction. Given that tempo plays a role in danceability, the data seems to suggest that music with tempo too high may not be danceable to, and that ~110-120bpm may be the sweet spot danceability. From the data, it is clear that FIFA is prioritizing music with high danceability. The average of 0.72 for a danceability score is greatly above the median of 0.55.\nAcousticness, Liveness The data indicates that songs are neither acoustic nor live recordings. This makes sense, as most if not all tracks are studio recorded and professionally produced before making it onto the FIFA playlist.\nValence Valence describes the \u0026ldquo;positiveness\u0026rdquo; of a song: whether it leaves the user feeling happy or sad. The score skew slightly higher than neutral (score of 0.5) but it does not appear that EA Sports has a strong preference for selecting \u0026ldquo;happy\u0026rdquo; music. We see the score spikes up in 2021, matching the high danceability score for the same year.\nSpeechiness Speechiness was interesting to interpret because my initial thought was that these values seemed way too low. From Spotify\u0026rsquo;s documentation, Speechiness should be in the range [0.66,1] for spoken word tracks such as podcasts, [0.33,0.66] for tracks that contain music and speech, either in sections or layered, and [0,0.33] for music heavy tracks. Given that anecdotally most if not all songs on the playlist contain words, the fact that the average scores were all in the [0.06,0.15] range every year surprised me. Nevertheless, this seems to suggest that FIFA prioritizes fairly melodic/ music heavy tracks with few or simple lyrics. We see the score is quite high in 2020, and this is due to the selection of a few rap heavy tracks such as \u0026ldquo;Unemployed\u0026rdquo;, \u0026ldquo;Where Do I Begin\u0026rdquo;, and \u0026ldquo;Where \u0026amp; When\u0026rdquo;. For these songs, there are notably a few sections where the artist is not rapping over a beat, leading to a high speechiness score.\nInstrumentalness Instrumentalness represents how music heavy (or vocal-less) a track is. At first glance, instrumentalness scores seem to contradict the conclusions made in the previous section, as the scores are quite low (~0.1 on a [0,1] scale). However, consulting historical distribution data, we see that the median instrumentalness score is 0.0005, which is one order of magnitude lower than the averages we see.\nKey\nKey represents the key a track is in, which consists of notes from A to G. Data about the song's key was not included in the charts above because it is categorical data that cannot be interpreted via averages. In the bar chart above, we see that the natural keys (not sharps or flats) are more prominently featured in the playlist. This reflects musical trends, according to this [website](https://www.hooktheory.com/cheat-sheet/key-popularity). \"C\",\"D\", \"A\", and \"G\" are the most popular keys to write songs in- more than a third of all songs are written in these keys. The chart above illustrates what proportion of the playlist each year was written in each key. These lines are all lines of best fit, to illustrate the trend of key usage over time rather than to identify the exact proportions for each year. From the chart, we see that the \u0026ldquo;G\u0026rdquo; key has halved in prominence. Interestingly, while \u0026ldquo;C\u0026rdquo;, \u0026ldquo;D\u0026rdquo;, \u0026ldquo;A\u0026rdquo;, and \u0026ldquo;G\u0026rdquo; are the most widely used keys in absolute terms, they are not the most commonly used in proportional terms. The period between 2018 and 2020 seemed to have the most even distribution in terms of key selection, especially if you ignore D#/Eb which has consistently low usage.\nIdeas for Future Work Multi label classification problem: given a song, classify which FIFA playlist it belongs to maybe instead of each year, classify by decade/ half a decade: years close to each other are quite similar ","date":"01","image":"images/post/fifa_playlist/preview.png","permalink":"/blog/visualizations/fifa-playlist/","tags":["Visualization","Python","Spotipy"],"title":"FIFA Playlist Analysis"},{"categories":["Project"],"contents":"Project aims to explore what factors makes a Premier League game is memorable/worth watching and generate a list of recommended Premier League games to watch.\nProject Github Repository\nTechniques/tools used:\nData Scraping: BeautifulSoup Python: numpy, pandas, matplotlib, seaborn, scikit-learn (Decision Trees, Random Forests, Linear Regression, Cross Validation, Pipeline), imblearn (SMOTE) Overview I analyzed this dataset of Premier League match statistics as well as data scraped from this FourFourTwo article about the 100 best Premier League matches of all time in order to determine the factors that make a Premier League match \u0026ldquo;good\u0026rdquo; or \u0026ldquo;memorable\u0026rdquo;. I then built a tool to recommend a list of the best Premier League matches of the past to watch. I performed feature engineering with a combination of the aforementioned dataset and additional data I scraped to find the strongest predictors regarding what makes a game memorable. I tested three different classifier models on the data: logistic regression, random forest, and decision trees. I used F1 score to evaluate the precision and recall of the models and concluded that a decision tree is the best model to use. I then fit a decision tree onto the entire dataset, performed hyperparameter tuning, and obtained an F1 score of 0.39 (recall score: 0.26, precision score: 0.81).\nMotivation Football (soccer) has always been a passion of mine. I grew up a Manchester United fan and idolized players such as Cristiano Ronaldo and Wayne Rooney, hoping to one day fulfill my dreams of playing in the Premier League. I fell well short of my lofty childhood ambitions but my love for the sport never faded and I follow the Premier League religiously to this day. I began following the Premier League during the 2010-2011 season, and I became used to watching games every week. During the COVID-19 pandemic, all Premier League games were postponed, and, craving my weekly football fix, I decided to build a tool to recommend past matches (prior to 2010-2011) to watch.\nMethodology To complete this project, I took the following steps:\nData Collection Data Cleaning Data Exploration Model Building Data Collection In this section, I describe the data that I obtained and the csv files they are stored in (accessible via Github Repository)\nEPL_Set.csv This kaggle dataset contains information from all Premier League games played since its inception (1992-1993). The information is only complete from the \u0026lsquo;95 - \u0026lsquo;96 season onwards and thus I discarded all data before this season. I stored this data in the file EPL_Set.csv.\nbest_games.csv This file contains data from this FourFourTwo article about the 100 best Premier League matches of all time. I obtained this data through web scraping. I analyzed this the data from the EPL_Set.csv dataset corresponding to each game in this list in order to determine the factors that make a Premier League match \u0026ldquo;good\u0026rdquo; or \u0026ldquo;memorable\u0026rdquo;. The relevant code is in the \u0026ldquo;best_games_scraper.py\u0026rdquo; file.\nteams.csv This file contains a list of all teams that have played in the Premier League since its inception. I obtained this data by scraping this wikipedia page. The relevant code is in the \u0026ldquo;team_scraper.py\u0026rdquo; file.\nrivalries.csv This file contains a list of all known Premier League rivalries. This is important because I later explored whether or not a rivalry game made a game more likely to be memorable. I obtained this data by scraping this wikipedia page. The relevant code is in the \u0026ldquo;rival_scraper.py\u0026rdquo; file.\npoints_history.csv This file contains a list of the total Premier League points accumulated by each Premier League team since the inception of the Premier League. This is important because I used points accumulated as a metric to measure team success/popularity, then explored whether or not team popularity/success contributes to making a match memorable. I obtained this data by scraping this wikipedia page. The relevant code is in the \u0026ldquo;total_points_scraper.py\u0026rdquo; file.\nData Cleaning In order to perform prepare the data for analysis, I performed the following steps:\nDrop Data Prior to \u0026lsquo;95 - \u0026lsquo;96 Season Data was incomplete prior to this season, so I could not use earlier data. Thus I removed the data from the dataset.\nDrop \u0026ldquo;Div\u0026rdquo; Column This column in the dataset indicated which division the game was played in. Since the games in this dataset are Premier League games, this column is irrelevant.\nStandardize Team Names As I collected data from several different sources, some team names were inconsistent. For example, \u0026ldquo;Queens Park Rangers\u0026rdquo; was named \u0026ldquo;QPR\u0026rdquo; and \u0026ldquo;Queens Park\u0026rdquo; in my data. To resolve this issue, I used the list of team names from the \u0026ldquo;teams.csv\u0026rdquo; file as the standard naming convention and used difflib library to find the closest name from the list of standard names to each name not in the list in the data. The relevant code can be found in the \u0026ldquo;standardize_names.py\u0026rdquo; file.\nStandardize Dates There was some inconsistency in the collected data as some dates are recorded in the format DD/MM/YYYY, while some are in the format MM/DD/YYYY. Furthermore, some dates only have two digits to represent the year. This posed a problem when I was trying to compare dates of different matches. To resolve this issue, I converted all dates to DD/MM/YYYY format.\n\u0026ldquo;Best Game\u0026rdquo; Column I added a column to represent whether a game is in the list of \u0026ldquo;Best Games\u0026rdquo; (binary variable). This will be the column I try to predict with my classification models. A problem that I had with this was when comparing game information between the games in the dataset and the games in the \u0026ldquo;Best Games\u0026rdquo; set, I found that the two sets of data did not always have matching dates for the same game (sometimes the dates were +/- one day). To resolve this issue, I used datetime and timedelta objects to allow for dates that differed by at most one day.\nAfter this stage, I ended up with a dataframe with 8740 entries and 9 features. The relevant code is in the \u0026ldquo;Data Cleaning and Exploration.ipynb\u0026rdquo; file.\nData Exploration In this section, I made 6 hypotheses regarding what constitutes a \u0026ldquo;Best Game\u0026rdquo; and added column features to the dataframe to test these hypotheses. The hypotheses are as follows:\nA statistically significant portion of games in the \u0026ldquo;Best Games\u0026rdquo; set \u0026hellip;\nInvolve popular/successful teams Are games played between rivals Involve comeback wins Are high scoring games Are close games Are played during the latter stages of the season Hypothesis 1 A statistically significant portion of games in the \u0026ldquo;Best Games\u0026rdquo; set involve popular/successful teams To test this hypothesis, I first calculated the frequency at which each team appeared in the set of \u0026ldquo;Best Games\u0026rdquo;. I then charted the data in a bar chart, shown below:\nFrom the chart above, it seems as though the more popular/successful teams appear in the \u0026ldquo;best games\u0026rdquo; set more often, confirming my hypothesis. The three teams with the highest count - Manchester United, Arsenal, and Liverpool - are three of most successful teams in Premier League history. I believe that this makes sense for the following reasons:\nMore successful teams tend to play in more high-stake games (games that have a large impact on the outcome of that year\u0026rsquo;s premier league title race). More successful teams tend to have higher viewership numbers for their games (more neutrals/rivals watch their games, and they usually have larger fanbases) and thus their games are more likely to remain in the collective memories of football fans for longer. More successful teams attract the most skillful players who produce the most highlight reel worthy moments, making their games more memorable. More successful teams are more likely to have more years in the premier league (3 teams get relegated to lower league divisions every year) and thus they play more premier league games, increasing their odds of playing in a memorable game. To quantify the \u0026ldquo;popularity\u0026rdquo; or \u0026ldquo;successfulness\u0026rdquo; of the teams in each game, I gave each team a \u0026ldquo;popularity score\u0026rdquo;, and summed up the two team\u0026rsquo;s popularity scores to derive the popularity score for each game. I made the assumption here that the most successful teams are the most popular, and the metric I used to determine the popularity score was the total number of points the team has earned in Premier League history (Teams earn 3 points for each match won, 1 for each draw, and 0 for losses). This data was scraped from this wikipedia page.\nCharting the popularity scores for each game in the \u0026ldquo;Best Games\u0026rdquo; set versus the rest of the games, I found that the median popularity score for games in the \u0026ldquo;Best Games\u0026rdquo; set is much higher than games not in the set, proving that memorable games involve successful/popular teams more often than not. The chart is shown below:\nVerdict: Correct\nHypothesis 2 A statistically significant portion of games in the \u0026ldquo;Best Games\u0026rdquo; set are games played between rivals Using collected data on a list of Premier League rivalries, I used pie charts to show the ratio of rival games to non-rival games in both the \u0026ldquo;Best Games\u0026rdquo; set and the rest of the games. The charts are shown below:\nStatistics: - Number of rival games in best games set: 26 - Number of non-rival games in best games set: 60 - Number of rival games in rest of data: 582 - Number of non-rival games in rest of data: 8072 As can be seen from the chart, the proportion of rival games in the \u0026ldquo;Best Games\u0026rdquo; set is much greater than the proportion of rival games in the rest of the data. This may be because there is extra emotional significance when it comes to games in which a team beats their fierce rivals, making the games more memorable. Rival games could possible also receive more media coverage, and higher viewership numbers mean that rival games are more likely to leave a greater impression on football audiences as a whole.\nIn terms of absolute numbers, there are a lot more rival games not in the \u0026lsquo;Best Games\u0026rsquo; set than there are in the rest of the data. A possible reason for this may be because when teams play in rival games, there is a lot more to lose (more pride at stake). As a result, teams may play extra cautiously in order not to lose the game. Defensive football rarely results in highlights or memorable plays and as a result the game as a whole is not memorable and not worthy of the \u0026lsquo;Best Games\u0026rsquo; title.\nVerdict: Correct\nHypothesis 3 A statistically significant portion of games in the \u0026ldquo;Best Games\u0026rdquo; set involve comeback wins I defined a comeback a game in which the team losing at half time wins the game, even though this is not always the case (teams can turn around a deficit in the same half that they fell behind in), as it was the best I could do given the collected data. I hypothesize that comeback games are more memorable than regular games because of the emotional rollercoasters that fans go through when watching these games.\nI again used pie charts to show the ratio of comeback to non-comeback games in both the \u0026ldquo;Best Games\u0026rdquo; set and the rest of the games. The charts are shown below:\nStatistics: - Number of comeback games in best games set: 18 - Number of non-comeback games in best games set: 68 - Number of comeback games in rest of data: 321 - Number of non-comeback games in rest of data: 8333 As shown in the chart above, comeback wins do appear in the \u0026ldquo;Best games\u0026rdquo; set at higher rates. However, it is important to note that the proportion of comeback games in the \u0026lsquo;Best Games\u0026rsquo; set is quite small. A reason for this could be that comebacks are rare, and there are other more significant elements of a game that make it memorable. Furthermore, there is also variance between comebacks. A team is much more likely to come back from one goal down than they are to come back from three goals down (which would make the game much more memorable than a one goal comeback).\nVerdict: Correct, but statistically insignificant\nHypothesis 4 A statistically significant portion of games in the \u0026ldquo;Best Games\u0026rdquo; set are high scoring games Football has traditionally been a low scoring game, especially in comparison to other popular sports such as basketball. As a result, high scoring games are often more memorable to fans. In order to test this hypothesis, I summed up the total number of goals for each game and charted this information for the \u0026ldquo;Best Games\u0026rdquo; set as well as the rest of the data in bar charts, shown below:\nStatistics:\n0 1 2 3 4 5 6 7 8 9 10 11 Best Games 2 5 1 10 7 21 8 11 11 5 4 1 Rest of Data 726 1598 2082 1843 1313 637 285 115 43 11 1 0 From the charts above, we can come to several conclusions:\nThe \u0026lsquo;Rest of Data\u0026rsquo; set is positively skewed while the \u0026lsquo;Best Games\u0026rsquo; set is more normally distributed. Only a small portion of games (9%) in the \u0026lsquo;Best Games\u0026rsquo; set involve low numbers of goals (low defined as less than the average number of goals scored during a football match, which is 2.6). Only ~2% of games involve 0 goals. The mode of the \u0026lsquo;Best Games\u0026rsquo; set (5) is much greater than the mode of the \u0026lsquo;Rest of Data\u0026rsquo; set (2). This suggests that the \u0026lsquo;Best Games\u0026rsquo; are typically high scoring. The mode is almost double the average number of goals scored in an football match. A larger proportion of total goals scored in the \u0026lsquo;Best Games\u0026rsquo; set are in the higher end of the range, suggesting that more often than not, \u0026lsquo;Best Games\u0026rsquo; are high scoring games The absolute number of games in the \u0026lsquo;Best Games\u0026rsquo; set with 10 or more goals is 5 compared to 1 in the rest of the data, even though the ratio of the number of games in the \u0026lsquo;Best Games\u0026rsquo; set to the number of games in the rest of the data is 8654:86 Verdict: Correct\nHypothesis 5 A statistically significant portion of games in the \u0026ldquo;Best Games\u0026rdquo; set are close games Close games keep fans on the edge of their seats, and it can be more fun to see your favorite team come out on top after a close game as opposed to a one-sided game. In order to test this hypothesis, I calculated the goal difference of each game (goals scored by winner - goals scored by loser). Drawn games have a goal difference of 0. I then charted this information for the \u0026ldquo;Best Games\u0026rdquo; set as well as the rest of the data in bar charts, shown below:\nStatistics:\n0 1 2 3 4 5 6 7 8 Best Games 18 41 11 6 1 5 1 1 2 Rest of Data 2252 3273 1825 807 333 117 37 7 3 Both graphs are positively skewed. The mode of the \u0026lsquo;Best Games\u0026rsquo; set is 1 goal, which suggests that a large proportion of the \u0026lsquo;Best Games\u0026rsquo; were close games (the winning team won by one goal). However, as can be seen from the rest of the data, the majority of the games have a goal difference of one so the large number of games with a goal diffrence of one in the \u0026lsquo;Best Games\u0026rsquo; set could just be due to a large sample size. The proportion of games with a goal difference of one in the \u0026lsquo;Best Games\u0026rsquo; set (48%) is greater than it\u0026rsquo;s counterpart in the rest of the data (38%), which suggests that my hypothesis is correct to a degree, although the two factors (appearance in \u0026lsquo;Best Games\u0026rsquo; set, small goal difference) may not be strongly correlated.\nVerdict: Correct, but not statistically significant\nHypothesis 6 A statistically significant portion of games in the \u0026ldquo;Best Games\u0026rdquo; set are played during the latter stages of the season Some Premier League games matter more than others. Games played towards the end of the season can have a large impact on the league table because at the latter stages of the season, players become fatigued both mentally and physically, so results at this stage can have a large impact on the morale of players. These games are more high-stakes as a result and can be more memorable. Furthermore, results at this stage can mathematically confirm a team\u0026rsquo;s place in the league table (confirmed as champions, confirmed spot in European competition, confirmed relegation, etc.) and the fate of their rivals or teams close to them in the table, which can have a major emotional and financial impact on all relevant teams. As a Manchester United fan, Manchester City\u0026rsquo;s 3-2 win over QPR in the final game of the 2011-12 season to win the premier league comes to mind.\nTo test this hypothesis, I assigned each month a number from 0 (August) to 9 (May), as Premier league seasons are played from August to May. I then charted the number of games played in each month. The results are as follows:\nStatistics:\n0 1 2 3 4 5 6 7 8 9 Best Games 4 13 12 10 6 3 8 4 10 16 Rest of Data 762 805 790 876 1265 862 770 850 1083 591 The mode of the \u0026lsquo;Best Games\u0026rsquo; data is 9 (May), suggesting that a large proportion of \u0026lsquo;Best Games\u0026rsquo; (~19%) are played towards the end of the season. The data is distributed bimodally, suggesting that my hypothesis is not quite correct. It appears that the \u0026lsquo;Best Games\u0026rsquo; are predominantly occur near the beginning and end of the season. This data surprises me a little as I would have expected more \u0026lsquo;Best Games\u0026rsquo; to occur in December (4). This is because firstly, more games are played in December, and secondly, a lot of big games (games starring high profile rivals) are played during the festive season to capitalize on the fact that there are more viewers and thus more revenue potential. An explanation for this could be that since December has the most games played, perform below their best due to accumulated fatigue.\nVerdict: Disproved\n\u0026lsquo;Best Games\u0026rsquo; occur predominantly near the beginning and the end of the season After this stage, I ended up with a dataframe with 8740 entries and 16 features. The relevant code is in the \u0026ldquo;Data Cleaning and Exploration.ipynb\u0026rdquo; file.\nModel Building and Performance Methodology I used classification algorithms to classify games as either in or out of the \u0026lsquo;Best Games\u0026rsquo; set. The list of games classified as part of the \u0026ldquo;Best Games\u0026rdquo; set served as the list of recommended games to rewatch during quarantine. I compared the results of three classification algorithms: Logistic Regression, Decision Tree, and Random Forest.\nThe metric I used to evaluate the models was the F1 score, which weighs precision and recall equally. I believe recall is an important metric because there is no point in creating a list of recommendations if a minimal amount of games on the list are actually worth rewatching. At the same time, precision is important because I do not want to waste my time watching a large number of games that should have been classified as unmemorable. I anticipated the precision of the model to be fairly low due to the highly imbalanced nature of the data.\nChoosing Features To minimize overfitting and training time, I only trained the model with features that correlate the most with the dependent variable. To do so, I decided to plot a correlation heatmap and take the 5 most highly correlated features.\nAccording to the heatmap, the top five features are:\nTotal Goals FTHG (Full Time Home Goals) FTAG (Full Time Away Goals) Rival Game Comeback However, we also see that Total Goals is very highly correlated to FTAG and FTHG. This is because Total Goals is the sum of FTAG and FTHG. To ensure collinearity, we will not consider FTAG and FTHG. We take the next 4 most highly correlated variables, resulting in the following features:\nTotal Goals Rival Game Comeback Popularity Score HTAG (Half Time Away Goals): also highly correlated with Total Goals HTHG (Half Time Hway Goals): also highly correlated with Total Goals Goal Difference: also highly correlated with Total Goals HTR (Half Time Result) Balancing Classes using SMOTE As previously mentioned, the data is highly imbalanced. Only 100 samples that are classified as a \u0026ldquo;Best Game\u0026rdquo; while 8640 samples are not. Since there was a clear imbalance between the number of samples in each class, I needed to either oversample data from the minority class (the \u0026lsquo;Best Games\u0026rsquo; class), or undersample data from the majority class to compensate. I chose to oversample from the minority class using SMOTE (Synthetic Minority Oversampling TEchnique) because if I undersample the classifier may not have enough data (only 200 samples) to classify the samples with high precision and recall.\nPipelines and KFold Cross Validation I created a Pipeline for each classifier (decision tree, random forest, logistic regression) to simplify the process of transforming the data (using SMOTE) then applying the classifier, as well as to ensure that I could cross validate the F1 scores of each classifier type by providing it with different parameters (input data). I performed cross validation by using the KFolds cross-validator to split the data into train/test splits. As per the Pareto Principle, I used an 80/20 train-test split, splitting the data into 5 folds.\nChoosing the Best Performing Classifier The performance of each classifier is as follows:\nLogistic Regression F1: 0.08881155233993385 Logistic Regression precision: 0.04732568063882119 Logistic Regression recall: 0.8291491841491843 Decision Tree F1: 0.0952839031489884 Decision Tree precision: 0.06264183157268263 Decision Tree recall: 0.25952547452547453 Random Forest F1: 0.08021591254261323 Random Forest precision: 0.052910848549946286 Random Forest recall: 0.24271228771228773 Since the decision tree had the highest F1 score, my final model was fitted using a decision tree.\nFinal Model Building I used GridSearchCV along with 5-fold cross validation to tune the hyperparameters. After fitting the model and outputting a prediction, the model\u0026rsquo;s performance was determined to be as follows:\nF1 score: 0.3893805309734513 Recall score: 0.2558139534883721 Precision score: 0.8148148148148148 Additionally, the confusion matrix is as follows:\nFrom the scores and the confusion matrix, we see that this model has a high precision and a low recall. This is surprising as it was the other way around previously (when deciding which model to choose). I think this was due to the hyperparameter tuning limiting the maximum depth of the decision tree, preventing overfitting. Overall, I think this model performed quite well; it is very precise, meaning that I do not have to waste my time watching boring games. While it was unable to correctly classify a majority of the minority class, I am not too concerned as the main objective of this project is to find any games worthy of watching- the number of games found does not matter too much (unless I finish watching all the recommended games and run out of games to watch).\nList of Recommendations and Observations The following are the games that were not initially in the \u0026ldquo;Best Games\u0026rdquo; set but were predicted to be a memorable game.\nLooking at these games, it seems that one common factor amongst them is the high-scoring nature of these games (at least 6 total goals score, which is very rare for football). The popularity scores for these teams are also relatively high- the range of scores is (0,2), and each of these games have popularity scores of at least 1.63.\nThe final list of games predicted to be a memorable game are as follows:\nDate HomeTeam AwayTeam 23/10/1999 Chelsea Arsenal 12/2/00 West Ham United Bradford City 25/02/2001 Manchester United Arsenal 29/09/2001 Tottenham Hotspur Manchester United 19/11/2001 Charlton Athletic West Ham United 7/2/04 Everton Manchester United 9/4/04 Arsenal Liverpool 22/01/2005 Norwich City Middlesbrough 1/2/05 Arsenal Manchester United 28/04/2007 Everton Manchester United 29/09/2007 Portsmouth Reading 29/12/2007 Tottenham Hotspur Reading 21/04/2009 Liverpool Arsenal 25/04/2009 Manchester United Tottenham Hotspur 20/09/2009 Manchester United Manchester City 22/11/2009 Tottenham Hotspur Wigan Athletic 20/11/2010 Arsenal Tottenham Hotspur 28/08/2011 Manchester United Arsenal 23/10/2011 Manchester United Manchester City 29/10/2011 Chelsea Arsenal 26/02/2012 Arsenal Tottenham Hotspur 22/04/2012 Manchester United Everton 17/11/2012 Arsenal Tottenham Hotspur 19/05/2013 West Bromwich Manchester United 23/01/2016 Norwich City Liverpool 14/08/2016 Arsenal Liverpool 26/11/2016 Swansea City Crystal Palace By looking at the complete list of recommended matches, we can see that the trend of the games being high scoring carries over; however, the popularity score does not. We can thus conclude that the largest predictor of whether or not a game is worthy of rewatching (according to the model) is the total number of goals scored in that game.\nThe jupyter notebook and relevant code can be found here. After this stage, I was able to generate a dataframe (which I converted to a csv file that can be found here) containing 27 recommended matches (not in any order).\nFuture Work Betting odds I believe that another predictor of whether or not a game is considered a \u0026ldquo;Best Game\u0026rdquo; is whether or not the game involved an upset, which is when a team defies the odds to beat the team favored to win the game. Data for betting odds for each of the matches was only available going back to 2000 so the 1995-1999 seasons would have to have been excluded from the analysis. It would be interesting to test this hypothesis and analyze the effect of the magnitude of the upset (a team with winning odds of 15/1 winning a game would be a much larger upset than a team with winning odds of 2/1)\nRanking the order of games in terms of rewatchability This project generates a list of recommended games to rewatch. What it does not do is differentiate between which games are more enjoyable to rewatch than others in the set of recommended games, which is important for people with limited time to rewatch games. A future project could involve ranking each game by rewatchability.\n","date":"14","image":"images/post/premier_league/preview.jpg","permalink":"/blog/projects/premier-league-game-recommender/","tags":["Classification","Python","Web Scraping"],"title":"Premier League Game Recommender"},{"categories":["Visualization"],"contents":"This post seeks to explore and visualize trends with summer olympics data. Link to Github Repository\n1. What proportion of the years gold medals did the winning country win? Apart from 1904 which was a huge outlier (USA won 78% of the available gold medals), the winner of each olympics typically win about 20-40% of the available gold medals (mean: 26.76%). There is a slight downward trend in the proportion of gold medals won by the winning country which suggests that the competition to win gold medals is becoming more and more intense. To dive deeper into causes of USA dominance in 1904: There were only 12 nations competing in the 1904 olympics. Furthermore, the US had 5x more athletes than all the other nations combined (523 of the 630 athletes represented the US). Why did so few countries countries send athletes to the olympics? This was only the third modern olympics, so there were not too many countries participating/invited to begin with (21 nations participated in the prior Olympics). This was also the first olympics hosted out of Europe (most countries participating in the early olympics were European countries), and St. Louis was a less than ideal location to host it (it was originally planned for Chicago; previous host cities were Athens and Paris), further contributing to the low number of visiting countries.\n2. What proportion of the years gold medals did the top 3 countries win relative to each other and the rest of the competition? Throughout the course of the olympics, on average, the top 3 nations win more medals than the rest of the competition combined. This data however is skewed by the earlier years of the competition where the winners were often much more dominant than the rest of the competition. If we only look at data from the last 10 olympics, we see that the top 3 nations win ~40% of the gold medals.\nLooking at the number of medals won (gold, silver, bronze) we see the other countries make up an event larger proportion of the total.\nFurther Exploration This article will be continuously updated with new content. In the future, I would like to test the following hypotheses:\nThe more economically developed a country is, the higher the probability of them being competitive in the olympics (winning more medals) people in economically developed countries have greater freedom to pursue and focus on sport. They also have more resources to train with. Economically developed countries can send more athletes to the games (more athletes qualify) and the athletes have bigger odds of winning their event. The host country performs better at each olympics The host country can add sports to the list of events, and they can add events that they are good at The home country\u0026rsquo;s athletes will generally have the most supporters cheering for them at each event (harder for people to travel to support their country) ","date":"13","image":"images/post/summer_olympics/preview.jpg","permalink":"/blog/visualizations/summer-olympics/","tags":["Visualization","Python","Web Scraping"],"title":"Summer Olympics"},{"categories":["Project"],"contents":"Project aims to predict the app store rating of a mobile game using linear regression, considering factors such as game size, genre, and price.\nLink to Github Repository\nData Cleaning I used mobile strategy games dataset from Kaggle to train and test my model. The dataset contained data on 16,847 different games. I performed data cleaning to extract data that I felt would be beneficial to train the model with and eliminate data that I deemed irrelevant to the model. I made the following changes:\nRemoved all entries without user rating data\nRemoved all entries with less than 100 user ratings to ensure that the ratings are credible (the higher volume of ratings the more likely they are a true representative of consumer opinion)\nI then added the following columns:\nSubtitle (y/n): an indicator variable describing whether or not the game had a subtitle. In-app purchases: in-app purchases range in price from $0 to $99.99. I grouped games into 4 quadrants by price: $0 - $24.99 $25 - $49.99 $50 - 74.99 $75 - $99.99 Number of words in description Age Rating: in the original dataset, there are 4 possible values for this column- 4+, 9+, 12+, and 17+. It is important to note that 9+, 12+, and 17+ games are also 4+ games, 12+ and 17+ games are also 9+ games, and 17+ games are also 12+ games. Thus, when creating indicator variables, I decided to make the categories \u0026lsquo;\u0026lt; 9\u0026rsquo;, \u0026lsquo;\u0026lt; 12\u0026rsquo;, and \u0026lsquo;\u0026lt; 17\u0026rsquo;. 4+ games satisfy \u0026lt; 9, 4+ and 9+ games satisfy \u0026lt; 12, 4+, 9+, and 12+ games satisfy \u0026lt; 17, while 17+ games do not satisfy any of the categories. Number of languages the game is offered in Size of game (in bytes) Genre: I created indicator variables for each possible game classification genre (there are 35 in total, examples include \u0026ldquo;Education\u0026rdquo;, \u0026ldquo;Finance\u0026rdquo;, and \u0026ldquo;Lifestyle\u0026rdquo;; I disregarded the \u0026ldquo;Game\u0026rdquo; genre because all data entries were marked with the \u0026ldquo;Game\u0026rdquo; genre. Time since last update (in days, as of April 20, 2020) After completing the data cleaning step of the project, I ended up with data from 2982 unique games to train and test my model with.\nModel Building and Performance I split the data into training and testing sets (50/50 split). I built the model using multiple linear regression and evaluated it using R-squared and Mean Absolute Error. I used the R-squared value to evaluate how accurately my model is able to predict mobile game ratings. I chose to use MAE to evaluate my model because it is relatively easy to interpret and outliers arenâ€™t particularly bad in for this type of model.\nThe model has an R-squared value of 0.1678 and a Mean Absolute Error of 0.37.\nFindings I used this backward elimination tutorial to perform backward elimination on the variables to find the most significant variables. Using an significance level of 0.05, the following variables were deemed to be significant (P-Value \u0026lt; Significance Level):\nPositive Coefficient of Regression\nSubtitle (y/n) In-app purchases ranging from $0 to $24.99 Age Rating \u0026lt; 12 Size of game ranging from 46.5 MB to 112 MB Size of game ranging from 112 MB to 221 MB Size of game larger than 221 MB Genre: Magazines and Newspaper Negative Coefficient of Regression\nAge Rating \u0026lt; 17 Genre: Adventure Genre: Board Genre: Reference Days Since Last Update We can make a few observations from the information above:\nInclude a subtitle (something like \u0026ldquo;Original Brain Training\u0026rdquo; for Sudoku) Include in-app purchases, but the price range for these items should be from $0 to $24.99 Cater to wider varieties of audiences, ensure that your game is playable by younger audiences (4+, 9+ range) Make games more detailed/ more content/ better graphics- larger install sizes are positively correlated with better ratings Genres such as \u0026ldquo;Magazines and Newspapers\u0026rdquo; are generally higher rated Genres such as \u0026ldquo;Adventure\u0026rdquo; and \u0026ldquo;Board\u0026rdquo; are generally lower rated. This could be because personal tastes vary more drastically for apps/games of this category, and people could leave distasteful ratings if the game is not built perfectly to their liking or if the game is frustrating to play for a person of average/below average skill level. Apps that were updated the most recently had lower ratings in general. I am unable to generate any concrete conclusions from this information, however a possible hypothesis is that there has been a recent trend in the game development industry of adding features that users dislike, such as increased advertisements or expensive in-app purchases that increase the disparity between paying and non-paying users. It would have been interesting to do an analysis on how the frequency of updates impacts average ratings. However, there was insufficient data to do so. However, it is important to note that using only the aforementioned significant variables to test and train a multiple linear regression model resulted in an R-squared value of 0.1684 and a Mean Absolute Error of 0.367, which are not significant improvements, so the observations generated do not carry much weight.\nThoughts and Conclusions In conclusion, it appears that multiple linear regression may not be a good model when modeling this scenario, though it is possible that it is hard to predict mobile game ratings to a high degree of accuracy in general as there is an element of randomness to ratings (hence the low R-squared value). Often times, people only rate the game when they have to and do not put much time or thought into it. Speaking from personal experience, I believe that people often make impulsive extreme ratings (ratings on the extreme of both the positive and negative ends of the grading scale) depending on their first impressions of the game, which skews the ratings and makes them harder to predict.\nAn alternate possibility to the low R-squared value is that mobile game ratings are influenced by a myriad of other factors not included in the dataset, such as whether or not the game prompts the user to give it a review.\nAlthough the model had a low R-squared value, I believe that the mean absolute error of 0.37 is not all that bad because in my opinion, it still reasonably conveys public opinion on the game. I personally subconsciously round mobile game ratings to the nearest whole number to associate it with a word (very bad, bad, average, good, very good) when gauging the quality of the game, and an error of 0.37 means that I would still be rounding to the same number in most cases. However, I understand that this could be different for others and this model may not be useful to others when they gauge the quality of a game.\nFrom the game designer\u0026rsquo;s point of view, when designing a game, it is important to keep the goals of designing the game in mind (to receive as high of a rating as possible, to reach as many people as possible, to generate as much revenue as possible, etc.). Hence, although it is never hurts to consider which factors positively or negatively impact game ratings (as stated in the \u0026ldquo;Findings\u0026rdquo; section), it is not the only thing to consider during game design.\nLimitations A few limitations of my model are:\nWhen counting the length of the game description, I noticed that some descriptions contained unicode for special characters such as emojis, and I was unable to find a way to exclude those from the count. I believe that there are more meaningful ways to categorize the in-app purchase prices, as from personal experience, certain price points are more common than others. For example, a majority of the games I have played in the past have only had in-app purchases worth $9.99 or less, so it might be beneficial to make a category from $0 to $9.99 instead of $0 to $24.99. Future Work Try to use different models to train and test the data (not just multiple linear regression) Potentially add different kinds of data (different columns) to the dataset ","date":"20","image":"images/post/app_store_rating/preview.jpg","permalink":"/blog/projects/app-store-game-ratings/","tags":["Regression","Python"],"title":"App Store Game Ratings"}]